{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e5815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import cdist\n",
    "import seaborn as sa\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f69ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the Dataset\n",
    "file_path = \"breast-cancer.csv\"  # Adjust file path if needed\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99642bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "                  Class    Age Menopause Tumor_Size Inv_Nodes Node_Caps  \\\n",
      "0  no-recurrence-events  30-39   premeno      30-34       0-2        no   \n",
      "1  no-recurrence-events  40-49   premeno      20-24       0-2        no   \n",
      "2  no-recurrence-events  40-49   premeno      20-24       0-2        no   \n",
      "3  no-recurrence-events  60-69      ge40      15-19       0-2        no   \n",
      "4  no-recurrence-events  40-49   premeno        0-4       0-2        no   \n",
      "\n",
      "   Deg_Malig Breast Breast_Quad Irradiat  \n",
      "0          3   left    left_low       no  \n",
      "1          2  right    right_up       no  \n",
      "2          2   left    left_low       no  \n",
      "3          2  right     left_up       no  \n",
      "4          2  right   right_low       no  \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Inspect the Dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d652c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Names:\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nColumn Names:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c68e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Class', 'Age', 'Menopause', 'Tumor_Size', 'Inv_Nodes', 'Node_Caps',\n",
      "       'Deg_Malig', 'Breast', 'Breast_Quad', 'Irradiat'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45fdc775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Identify the Target Column (\"Class\")\n",
    "if 'Class' in df.columns:\n",
    "    target_column = 'Class'\n",
    "else:\n",
    "    raise ValueError(\"Class column not found! Please check the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a87e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "        label_encoders[column] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71e7cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Split Data into Training & Testing Sets\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59b38dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Data Preprocessing (Standardization)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fbd9a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution Before ADASYN:\n",
      "Counter({0: 164, 1: 64})\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Check Class Imbalance\n",
    "print(\"\\nClass Distribution Before ADASYN:\")\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f77b66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Apply Gaussian Mixture Model (GMM)\n",
    "k = 5  # Number of clusters\n",
    "gmm = GaussianMixture(n_components=k, random_state=42)\n",
    "clusters = gmm.fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd48a435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clusters: [2 2 3 4 2 0 3 2 2 4 2 3 0 3 2 0 4 3 1 2 0 3 2 2 3 3 2 3 1 3 4 3 2 2 2 3 3\n",
      " 3 2 0 3 2 2 4 2 1 0 0 2 0 0 3 3 0 3 4 2 1 1 3 2 2 4 3 2 3 4 2 1 0 0 2 3 2\n",
      " 3 2 4 3 3 1 0 1 3 3 3 1 2 2 1 3 4 2 2 3 2 3 4 3 0 2 4 2 0 2 2 3 0 0 2 3 1\n",
      " 0 2 0 3 3 2 3 3 2 2 3 2 2 3 2 3 2 3 0 0 0 2 1 4 2 3 2 3 3 3 2 3 2 0 2 1 2\n",
      " 2 0 2 2 2 2 0 0 2 2 2 0 0 3 3 2 3 3 2 4 2 2 4 3 2 1 3 3 2 3 3 3 3 3 0 2 2\n",
      " 2 0 3 3 3 2 2 0 3 4 3 3 3 3 3 3 4 2 3 3 3 3 2 2 2 3 2 2 2 0 0 3 2 3 3 3 3\n",
      " 3 1 2 2 4 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClusters:\", clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5525132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Filter Clusters with More Minority Instances\n",
    "df_train_clustered = X_train.copy()\n",
    "df_train_clustered['cluster'] = clusters\n",
    "df_train_clustered[target_column] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea62ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_clusters = []\n",
    "for c in np.unique(clusters):\n",
    "    cluster_data = df_train_clustered[df_train_clustered['cluster'] == c]\n",
    "    minority_count = cluster_data[target_column].sum()\n",
    "    majority_count = len(cluster_data) - minority_count\n",
    "    imbalance_ratio = (majority_count + 1) / (minority_count + 1)\n",
    "    if imbalance_ratio < 1.5:\n",
    "        filtered_clusters.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7c025e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Clusters: [0, 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFiltered Clusters:\", filtered_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61cd5eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Compute Sampling Weight for Each Cluster\n",
    "def compute_sampling_weight(cluster_data, target_column, minority_count, X_train):\n",
    "    feature_data = cluster_data.drop(columns=['cluster', target_column]).values\n",
    "    \n",
    "    # Compute pairwise Euclidean distances\n",
    "    pairwise_distances = cdist(feature_data, feature_data, metric='euclidean')\n",
    "    \n",
    "    # Take the mean of the upper triangle (excluding diagonal)\n",
    "    avg_minority_dist = np.mean(pairwise_distances[np.triu_indices(len(feature_data), k=1)])\n",
    "    \n",
    "    print(f\"Cluster {cluster_data['cluster'].iloc[0]} - Avg Euclidean Distance:\", avg_minority_dist)\n",
    "    \n",
    "    density_factor = minority_count / (avg_minority_dist ** X_train.shape[1])\n",
    "    sparsity_factor = 1 / density_factor\n",
    "    \n",
    "    return sparsity_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54cb468d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 - Avg Euclidean Distance: 4.125837518638979\n",
      "Cluster 4 - Avg Euclidean Distance: 3.5113134343470382\n"
     ]
    }
   ],
   "source": [
    "sparsity_sum = sum(compute_sampling_weight(\n",
    "    df_train_clustered[df_train_clustered['cluster'] == f], \n",
    "    target_column, \n",
    "    len(df_train_clustered[df_train_clustered['cluster'] == f]), \n",
    "    X_train\n",
    ") for f in filtered_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2577d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 - Avg Euclidean Distance: 4.125837518638979\n",
      "Cluster 4 - Avg Euclidean Distance: 3.5113134343470382\n"
     ]
    }
   ],
   "source": [
    "sampling_weights = {\n",
    "    f: compute_sampling_weight(df_train_clustered[df_train_clustered['cluster'] == f], target_column, len(df_train_clustered[df_train_clustered['cluster'] == f]), X_train) / sparsity_sum\n",
    "    for f in filtered_clusters\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58f57356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling Weights: {0: 0.6995958370205877, 4: 0.30040416297941225}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSampling Weights:\", sampling_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a69face2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Apply ADASYN for Oversampling\n",
    "X_resampled = pd.DataFrame()\n",
    "y_resampled = pd.Series(dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "785886d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_id in filtered_clusters:\n",
    "    cluster_data = df_train_clustered[df_train_clustered['cluster'] == cluster_id]\n",
    "    X_cluster = cluster_data.drop(columns=['cluster', target_column])\n",
    "    y_cluster = cluster_data[target_column]\n",
    "    \n",
    "    if len(y_cluster) < 2:  # Skip clusters with fewer than 2 samples\n",
    "        continue\n",
    "    \n",
    "    num_samples = int(len(y_train) * sampling_weights[cluster_id])\n",
    "    \n",
    "    adasyn = ADASYN(n_neighbors=min(len(y_cluster) - 1, 4), random_state=42)\n",
    "    X_cluster_resampled, y_cluster_resampled = adasyn.fit_resample(X_cluster, y_cluster)\n",
    "    \n",
    "    X_resampled = pd.concat([X_resampled, X_cluster_resampled])\n",
    "    y_resampled = pd.concat([y_resampled, y_cluster_resampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "512000bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution After ADASYN:\n",
      "Counter({0: 28, 1: 24})\n"
     ]
    }
   ],
   "source": [
    "# Step 13: Check Class Distribution After ADASYN\n",
    "print(\"\\nClass Distribution After ADASYN:\")\n",
    "print(Counter(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3122b3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 14: Train a Classification Model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87da5c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 15: Make Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bb8e0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 16: Compute Accuracy and ROC AUC Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c29e048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7069\n",
      "ROC AUC Score: 0.6088\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "500b5225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7414\n",
      "ROC AUC Score: 0.7104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Step 15: Make Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Step 16: Compute Accuracy and ROC AUC Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3116437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7069\n",
      "ROC AUC Score: 0.6088\n",
      "Geometric Mean: 0.4813\n",
      "F1 Score: 0.3704\n",
      "PR AUC Score: 0.5675\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, f1_score, precision_recall_curve, auc\n",
    ")\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "# Step 13: Train a Classification Model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)  # Train on resampled data\n",
    "\n",
    "# Step 14: Make Predictions\n",
    "y_pred = clf.predict(X_test)  # Predicted labels\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]  # Probability of positive class\n",
    "\n",
    "# Step 15: Compute Accuracy and ROC AUC Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Compute Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "g_mean = geometric_mean_score(y_test, y_pred)  # Geometric Mean\n",
    "f1 = f1_score(y_test, y_pred)  # F1-score\n",
    "\n",
    "# Compute Precision-Recall Curve and PR AUC\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = auc(recall, precision)  # Area Under Precision-Recall Curve\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"Geometric Mean: {g_mean:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"PR AUC Score: {pr_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
