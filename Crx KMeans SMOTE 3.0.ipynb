{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec5ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import seaborn as sa\n",
    "# Final step: Model training & evaluation can be done on X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45edf0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the Dataset\n",
    "df = pd.read_csv('crx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79e07402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "  Unnamed: 0 Unnamed: 1  Unnamed: 2 Unnamed: 3 A1 A2 A3    A4 A5 A6  A7 A8 A9  \\\n",
      "0          b      30.83       0.000          u  g  w  v  1.25  t  t   1  f  g   \n",
      "1          a      58.67       4.460          u  g  q  h  3.04  t  t   6  f  g   \n",
      "2          a       24.5       0.500          u  g  q  h  1.50  t  f   0  f  g   \n",
      "3          b      27.83       1.540          u  g  w  v  3.75  t  t   5  t  g   \n",
      "4          b      20.17       5.625          u  g  w  v  1.71  t  f   0  f  s   \n",
      "\n",
      "   A10  A11 Class  \n",
      "0  202    0     +  \n",
      "1   43  560     +  \n",
      "2  280  824     +  \n",
      "3  100    3     +  \n",
      "4  120    0     +  \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Inspect the Dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())  # Display first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "513375f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Names:\n",
      "Index(['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'A1', 'A2',\n",
      "       'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11', 'Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns)  # Check column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c79b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Identify the Target Column (\"Class\")\n",
    "if 'Class' in df.columns:\n",
    "    target_column = 'Class'\n",
    "else:\n",
    "    raise ValueError(\"Class column not found! Please check the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7304d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "        label_encoders[column] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "987b93b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3  A1  A2  A3    A4  A5  A6  \\\n",
      "0             2         156       0.000           2   1  13   8  1.25   1   1   \n",
      "1             1         328       4.460           2   1  11   4  3.04   1   1   \n",
      "2             1          89       0.500           2   1  11   4  1.50   1   0   \n",
      "3             2         125       1.540           2   1  13   8  3.75   1   1   \n",
      "4             2          43       5.625           2   1  13   8  1.71   1   0   \n",
      "..          ...         ...         ...         ...  ..  ..  ..   ...  ..  ..   \n",
      "685           2          52      10.085           3   3   5   4  1.25   0   0   \n",
      "686           1          71       0.750           2   1   2   8  2.00   0   1   \n",
      "687           1          97      13.500           3   3   6   3  2.00   0   1   \n",
      "688           2          20       0.205           2   1   1   8  0.04   0   0   \n",
      "689           2         197       3.375           2   1   2   4  8.29   0   0   \n",
      "\n",
      "     A7  A8  A9  A10  A11  \n",
      "0     1   0   0   42    0  \n",
      "1     6   0   0  118  560  \n",
      "2     0   0   0   74  824  \n",
      "3     5   1   0    1    3  \n",
      "4     0   0   2    8    0  \n",
      "..   ..  ..  ..  ...  ...  \n",
      "685   0   0   0   67    0  \n",
      "686   2   1   0   40  394  \n",
      "687   1   1   0   40    1  \n",
      "688   0   0   0   74  750  \n",
      "689   0   1   0    0    0  \n",
      "\n",
      "[690 rows x 15 columns]\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "685    1\n",
      "686    1\n",
      "687    1\n",
      "688    1\n",
      "689    1\n",
      "Name: Class, Length: 690, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Split Data into Training & Testing Sets\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52654b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3  A1  A2  A3      A4  A5  \\\n",
      "278           2          90      13.500           3   3   6   3   0.000   0   \n",
      "110           2         137       3.500           2   1  13   8   3.500   1   \n",
      "82            2         235       0.500           2   1  10   8   0.250   1   \n",
      "51            2         106       1.000           2   1  11   8   1.750   1   \n",
      "218           2         308       9.625           2   1   5   8   8.665   1   \n",
      "..          ...         ...         ...         ...  ..  ..  ..     ...  ..   \n",
      "71            2         195       4.000           2   1   4   1  12.500   1   \n",
      "106           2         135       1.165           2   1   9   8   0.500   1   \n",
      "270           2         217       0.000           0   0   0   0   0.000   0   \n",
      "435           2          33       0.000           3   3   6   3   0.000   0   \n",
      "102           2          29       5.000           2   1  11   8   0.375   1   \n",
      "\n",
      "     A6  A7  A8  A9  A10  A11  \n",
      "278   0   0   0   0  170    0  \n",
      "110   1   3   1   0   87    0  \n",
      "82    0   0   0   2   75    0  \n",
      "51    0   0   1   0   74    0  \n",
      "218   1   5   0   0    0    0  \n",
      "..   ..  ..  ..  ..  ...  ...  \n",
      "71    0   0   1   0  170    0  \n",
      "106   0   0   0   2   74    0  \n",
      "270   0   0   0   1  170    0  \n",
      "435   1   4   0   0  124    1  \n",
      "102   1   2   0   0    0   38  \n",
      "\n",
      "[552 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79dc5efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3  A1  A2  A3   A4  A5  A6  \\\n",
      "286           1         349         1.5           2   1   6   3  0.0   0   1   \n",
      "511           1         271         4.0           2   1   8   5  0.0   1   0   \n",
      "257           2          41         0.0           2   1   4   8  0.5   0   0   \n",
      "336           2         277         6.5           2   1   2   8  1.0   0   0   \n",
      "318           2          34         0.0           3   3  10   1  0.0   0   0   \n",
      "\n",
      "     A7  A8  A9  A10  A11  \n",
      "286   2   1   0   40  105  \n",
      "511   0   0   0    1  960  \n",
      "257   0   0   0   17    0  \n",
      "336   0   1   0    0  228  \n",
      "318   0   1   2  136    1  \n"
     ]
    }
   ],
   "source": [
    "print(X_test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d0fc0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278    1\n",
      "110    1\n",
      "82     1\n",
      "51     0\n",
      "218    0\n",
      "      ..\n",
      "71     1\n",
      "106    1\n",
      "270    0\n",
      "435    1\n",
      "102    1\n",
      "Name: Class, Length: 552, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccf594ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286    1\n",
      "511    0\n",
      "257    1\n",
      "336    1\n",
      "318    0\n",
      "      ..\n",
      "333    1\n",
      "507    0\n",
      "24     0\n",
      "158    0\n",
      "518    0\n",
      "Name: Class, Length: 138, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adab6495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Data Preprocessing (Standardization)\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e53dfbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution Before SMOTE:\n",
      "Counter({1: 315, 0: 237})\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Check Class Imbalance\n",
    "print(\"\\nClass Distribution Before SMOTE:\")\n",
    "print(Counter(y_train))  # Count of each class in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a48fac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Apply K-Means Clustering\n",
    "k = 5  # Number of clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96d54759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Clusters: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 3 0 0 3 0 0\n",
      " 3 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0\n",
      " 0 0 0 0 0 0 0 0 3 0 0 0 0 0 3 0 0 0 0 0 2 0 0 0 0 0 3 0 0 0 0 0 3 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 2 0 0 0 0 3 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 0\n",
      " 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 3 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0\n",
      " 3 0 0 0 0 3 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 3 0 3 0 0 0 0 3 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 3 0 3 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0\n",
      " 0 0 0 0 3 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Clusters:\",clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "634e619e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3  A1  A2  A3      A4  A5  \\\n",
      "278           2          90      13.500           3   3   6   3   0.000   0   \n",
      "110           2         137       3.500           2   1  13   8   3.500   1   \n",
      "82            2         235       0.500           2   1  10   8   0.250   1   \n",
      "51            2         106       1.000           2   1  11   8   1.750   1   \n",
      "218           2         308       9.625           2   1   5   8   8.665   1   \n",
      "..          ...         ...         ...         ...  ..  ..  ..     ...  ..   \n",
      "71            2         195       4.000           2   1   4   1  12.500   1   \n",
      "106           2         135       1.165           2   1   9   8   0.500   1   \n",
      "270           2         217       0.000           0   0   0   0   0.000   0   \n",
      "435           2          33       0.000           3   3   6   3   0.000   0   \n",
      "102           2          29       5.000           2   1  11   8   0.375   1   \n",
      "\n",
      "     A6  A7  A8  A9  A10  A11  cluster  \n",
      "278   0   0   0   0  170    0        0  \n",
      "110   1   3   1   0   87    0        0  \n",
      "82    0   0   0   2   75    0        0  \n",
      "51    0   0   1   0   74    0        0  \n",
      "218   1   5   0   0    0    0        0  \n",
      "..   ..  ..  ..  ..  ...  ...      ...  \n",
      "71    0   0   1   0  170    0        0  \n",
      "106   0   0   0   2   74    0        0  \n",
      "270   0   0   0   1  170    0        0  \n",
      "435   1   4   0   0  124    1        0  \n",
      "102   1   2   0   0    0   38        0  \n",
      "\n",
      "[552 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Filter Clusters with More Minority Instances\n",
    "df_train_clustered = X_train.copy()\n",
    "df_train_clustered['cluster'] = clusters\n",
    "print(df_train_clustered)\n",
    "df_train_clustered[target_column] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "789d2c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "     Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3  A1  A2  A3      A4  A5  \\\n",
      "278           2          90      13.500           3   3   6   3   0.000   0   \n",
      "110           2         137       3.500           2   1  13   8   3.500   1   \n",
      "82            2         235       0.500           2   1  10   8   0.250   1   \n",
      "51            2         106       1.000           2   1  11   8   1.750   1   \n",
      "218           2         308       9.625           2   1   5   8   8.665   1   \n",
      "..          ...         ...         ...         ...  ..  ..  ..     ...  ..   \n",
      "71            2         195       4.000           2   1   4   1  12.500   1   \n",
      "106           2         135       1.165           2   1   9   8   0.500   1   \n",
      "270           2         217       0.000           0   0   0   0   0.000   0   \n",
      "435           2          33       0.000           3   3   6   3   0.000   0   \n",
      "102           2          29       5.000           2   1  11   8   0.375   1   \n",
      "\n",
      "     A6  A7  A8  A9  A10  A11  cluster  Class  \n",
      "278   0   0   0   0  170    0        0      1  \n",
      "110   1   3   1   0   87    0        0      1  \n",
      "82    0   0   0   2   75    0        0      1  \n",
      "51    0   0   1   0   74    0        0      0  \n",
      "218   1   5   0   0    0    0        0      0  \n",
      "..   ..  ..  ..  ..  ...  ...      ...    ...  \n",
      "71    0   0   1   0  170    0        0      1  \n",
      "106   0   0   0   2   74    0        0      1  \n",
      "270   0   0   0   1  170    0        0      0  \n",
      "435   1   4   0   0  124    1        0      1  \n",
      "102   1   2   0   0    0   38        0      1  \n",
      "\n",
      "[504 rows x 17 columns]\n",
      "310\n",
      "194\n",
      "1\n",
      "     Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3  A1  A2  A3   A4  A5  A6  \\\n",
      "317           2          16        22.0           1   2   6   7  0.0   0   0   \n",
      "\n",
      "     A7  A8  A9  A10     A11  cluster  Class  \n",
      "317   0   1   1  125  100000        1      0  \n",
      "0\n",
      "1\n",
      "2\n",
      "     Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3  A1  A2  A3      A4  A5  \\\n",
      "29            2         252       1.040           2   1  13   8   5.000   1   \n",
      "167           1         171       0.540           2   1   3   8   0.040   1   \n",
      "117           2         305       6.500           2   1   9   8   6.290   1   \n",
      "245           2         179       3.040           3   3   2   4   2.040   1   \n",
      "180           2         279       0.290           2   1   2   1  15.000   1   \n",
      "237           2          55       7.500           2   1   1   8   1.415   1   \n",
      "584           1         127      15.000           3   3   5   9   0.000   1   \n",
      "67            2         100       0.375           2   1  10   8   0.250   1   \n",
      "217           2         314      11.500           2   1   6   3   5.000   1   \n",
      "\n",
      "     A6  A7  A8  A9  A10    A11  cluster  Class  \n",
      "29    1   6   1   0  136  10000        2      0  \n",
      "167   0   0   0   0  122  11177        2      0  \n",
      "117   1  15   0   0    0  11202        2      0  \n",
      "245   1   1   1   0   34  18027        2      0  \n",
      "180   1  20   0   0    0  15000        2      0  \n",
      "237   1   1   0   0  159   9800        2      0  \n",
      "584   0   0   0   0    0  13212        2      0  \n",
      "67    1   3   0   0   67  15108        2      0  \n",
      "217   1   5   0   0    0   8851        2      0  \n",
      "0\n",
      "9\n",
      "3\n",
      "     Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3  A1  A2  A3      A4  A5  \\\n",
      "599           2          47       2.415           2   1   2   8   2.000   1   \n",
      "559           1          73       2.290           2   1  11   4   2.290   1   \n",
      "352           2          69      11.500           3   3  10   8   1.500   0   \n",
      "588           2         113       1.750           3   3   2   8   1.000   1   \n",
      "234           1         326      21.000           2   1   7   1  10.000   1   \n",
      "33            1         212       5.125           2   1   5   8   5.000   1   \n",
      "578           2         229       1.625           2   1   2   8   1.500   1   \n",
      "184           1          68       5.665           2   1  11   8   2.585   1   \n",
      "68            2          36       6.500           2   1  13   4   1.460   1   \n",
      "548           2         179       1.000           2   1  14   8   0.750   1   \n",
      "589           2          98       0.580           2   1   2   8   0.290   1   \n",
      "596           1         272       3.000           2   1   2   8   2.375   1   \n",
      "126           2         279       2.500           2   1  10   1   2.500   1   \n",
      "287           2         140       0.580           2   1  13   8   0.290   0   \n",
      "445           1         349      11.250           2   1   6   3   0.000   0   \n",
      "157           1         341      15.000           2   1   5   9   0.000   1   \n",
      "575           2         170       0.165           3   3   2   4   3.250   1   \n",
      "139           1         116      13.500           2   1  11   4   5.000   1   \n",
      "147           1         239       7.540           3   3  11   4   8.000   1   \n",
      "558           2         298       0.040           2   1  14   4   0.040   1   \n",
      "183           1         321      19.500           2   1   2   8   5.500   1   \n",
      "323           2         287       0.205           3   3   9   8   0.250   1   \n",
      "496           1          94       0.875           2   1  14   4   1.040   1   \n",
      "505           2         160      19.500           2   1   2   8   7.000   1   \n",
      "580           2         163       0.830           2   1  14   8   1.335   1   \n",
      "32            2         291       7.585           2   1   7   1   7.585   1   \n",
      "230           2          96       3.500           2   1   3   8   0.625   1   \n",
      "378           2         190       1.335           2   1   7   1   0.125   0   \n",
      "492           2         230       9.500           2   1  10   8   6.500   1   \n",
      "187           2         240       5.000           2   1   2   8   5.000   1   \n",
      "52            2         215       2.040           2   1  13   8   0.040   1   \n",
      "455           2         205      18.125           2   1  13   8   0.085   0   \n",
      "561           2         114       1.125           2   1  14   4   1.250   1   \n",
      "205           1         200      12.000           2   1  11   4  14.000   1   \n",
      "13            2         282       6.040           2   1   9   8   0.040   0   \n",
      "252           1          19      11.000           2   1  14   4   1.000   1   \n",
      "160           2         123       2.000           2   1  14   4   1.000   1   \n",
      "\n",
      "     A6  A7  A8  A9  A10   A11  cluster  Class  \n",
      "599   1  11   1   0   40  3000        3      0  \n",
      "559   1   7   1   0   15  2384        3      0  \n",
      "352   0   0   1   0    0  4000        3      1  \n",
      "588   1   5   1   0   23  5777        3      0  \n",
      "234   1  13   0   0    0  6700        3      0  \n",
      "33    0   0   1   0    0  4000        3      0  \n",
      "578   1  10   0   0   36  4700        3      0  \n",
      "184   1   7   0   0   11  3257        3      0  \n",
      "68    1   7   0   0  159  2954        3      0  \n",
      "548   1   7   1   0   90  4071        3      0  \n",
      "589   1   7   1   0  167  5124        3      0  \n",
      "596   1   8   1   0  108  4159        3      0  \n",
      "126   1  12   1   0  113  2510        3      0  \n",
      "287   1   1   0   0   90  2803        3      1  \n",
      "445   0   0   0   0  170  5200        3      1  \n",
      "157   1  14   0   0    0  3376        3      0  \n",
      "575   1   1   1   0  120  8000        3      0  \n",
      "139   1   2   0   0    0  5000        3      0  \n",
      "147   1  14   0   0    0  2300        3      0  \n",
      "558   0   0   0   0    0  3000        3      0  \n",
      "183   1   7   0   0    0  3000        3      0  \n",
      "323   1  11   0   0  103  2732        3      0  \n",
      "496   0   0   1   0   23  5860        3      0  \n",
      "505   1  16   0   0    0  5000        3      0  \n",
      "580   1   8   1   0   81  3290        3      0  \n",
      "32    1  15   1   0    0  5000        3      0  \n",
      "230   1   7   0   0    0  7059        3      0  \n",
      "378   0   0   1   0  122  4500        3      1  \n",
      "492   1  14   0   0   61  4607        3      0  \n",
      "187   1   7   0   0    0  3065        3      0  \n",
      "52    0   0   1   0  111  5800        3      0  \n",
      "455   0   0   0   0   86  3552        3      1  \n",
      "561   0   0   0   0    0  5298        3      0  \n",
      "205   1   8   0   0    0  6590        3      0  \n",
      "13    0   0   0   0    0  2690        3      0  \n",
      "252   1  11   0   0    0  3000        3      0  \n",
      "160   1   4   0   0   15  7544        3      0  \n",
      "5\n",
      "32\n",
      "4\n",
      "     Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3  A1  A2  A3    A4  A5  A6  \\\n",
      "243           1          30         7.5           2   1  11   8  2.71   1   1   \n",
      "\n",
      "     A7  A8  A9  A10    A11  cluster  Class  \n",
      "243   5   0   0  170  26726        4      0  \n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "filtered_clusters = []\n",
    "for c in np.unique(clusters):\n",
    "    cluster_data = df_train_clustered[df_train_clustered['cluster'] == c]\n",
    "    print(c)\n",
    "    print(cluster_data)\n",
    "    minority_count = cluster_data[target_column].sum() # Count of minority class\n",
    "    print(minority_count)\n",
    "    majority_count = len(cluster_data) - minority_count\n",
    "    print(majority_count)\n",
    "    imbalance_ratio = (majority_count + 1) / (minority_count + 1)  # Avoid division by zero\n",
    "    if imbalance_ratio < 1.5:  # Imbalance ratio threshold\n",
    "        filtered_clusters.append(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8ceee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Clusters: [0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFiltered Clusters:\", filtered_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69cb356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def compute_sampling_weight(cluster_data, target_column, minority_count, X_train):\n",
    "    # Extract only feature columns (excluding 'cluster' and target column)\n",
    "    feature_data = cluster_data.drop(columns=['cluster', target_column]).values\n",
    "\n",
    "    # Compute pairwise Euclidean distances for all points in the cluster\n",
    "    pairwise_distances = cdist(feature_data, feature_data, metric='euclidean')\n",
    "\n",
    "    # Take the mean of the lower triangle of the distance matrix (excluding diagonal)\n",
    "    avg_minority_dist = np.mean(pairwise_distances[np.triu_indices(len(feature_data), k=1)])\n",
    "\n",
    "    print(avg_minority_dist)\n",
    "\n",
    "    # Compute density and sparsity factors\n",
    "    density_factor = minority_count / (avg_minority_dist ** X_train.shape[1])\n",
    "    sparsity_factor = 1 / density_factor\n",
    "\n",
    "    return sparsity_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aef231e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424.4851716291356\n"
     ]
    }
   ],
   "source": [
    "# Compute the total sparsity sum\n",
    "sparsity_sum = sum(compute_sampling_weight(df_train_clustered[df_train_clustered['cluster'] == f], target_column, len(df_train_clustered[df_train_clustered['cluster'] == f]), X_train) for f in filtered_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bab61db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424.4851716291356\n",
      "\n",
      "Sampling Weights: {0: 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Compute sampling weights\n",
    "sampling_weights = {\n",
    "    f: compute_sampling_weight(df_train_clustered[df_train_clustered['cluster'] == f], target_column, len(df_train_clustered[df_train_clustered['cluster'] == f]), X_train) / sparsity_sum\n",
    "    for f in filtered_clusters\n",
    "}\n",
    "\n",
    "print(\"\\nSampling Weights:\", sampling_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35f5aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Apply SMOTE for Oversampling\n",
    "X_resampled = pd.DataFrame()\n",
    "y_resampled = pd.Series(dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "327e6df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_id in filtered_clusters:\n",
    "    cluster_data = df_train_clustered[df_train_clustered['cluster'] == cluster_id]\n",
    "    X_cluster = cluster_data.drop(columns=['cluster', target_column])\n",
    "    y_cluster = cluster_data[target_column]\n",
    "    \n",
    "    num_samples = int(len(y_train) * sampling_weights[cluster_id])  # Compute number of samples to generate\n",
    "    \n",
    "    smote = SMOTE(k_neighbors=min(3, len(y_cluster) - 1), random_state=42)\n",
    "    X_cluster_resampled, y_cluster_resampled = smote.fit_resample(X_cluster, y_cluster)\n",
    "    \n",
    "    X_resampled = pd.concat([X_resampled, X_cluster_resampled])\n",
    "    y_resampled = pd.concat([y_resampled, y_cluster_resampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c614351c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before resampling: Counter({1: 315, 0: 237})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Before resampling:\", Counter(y_train))  # Original class distribution\n",
    "# print(\"After resampling:\", Counter(y_resampled))  # Resampled class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70ccfcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying SMOTE: Counter({1: 315, 0: 315})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After applying SMOTE:\", Counter(y_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98642508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Check for NaNs\n",
    "if pd.DataFrame(X_resampled).isnull().values.any():\n",
    "    print(\"X_resampled contains NaN values\")\n",
    "    X_resampled = pd.DataFrame(X_resampled).fillna(method=\"ffill\").values  # Fill missing values\n",
    "\n",
    "# Ensure finite values\n",
    "X_resampled = np.nan_to_num(X_resampled)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6828745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (552, 15)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1aa0406b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.8551\n",
      "ROC AUC Score: 0.9069\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import numpy as np  # Ensure NumPy is imported\n",
    "\n",
    "# Step 2: Ensure data is in the correct format\n",
    "X_resampled = np.array(X_resampled) if not isinstance(X_resampled, np.ndarray) else X_resampled\n",
    "y_resampled = np.ravel(y_resampled)\n",
    "\n",
    "X_test = np.array(X_test) if not isinstance(X_test, np.ndarray) else X_test\n",
    "y_test = np.ravel(y_test)\n",
    "\n",
    "# Step 3: Train the Model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Step 4: Make Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1] if clf.n_classes_ == 2 else clf.predict_proba(X_test)\n",
    "\n",
    "# Step 5: Compute Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr') if len(np.unique(y_test)) > 2 else roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c6a4a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7609\n",
      "ROC AUC Score: 0.8282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Step 15: Make Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Step 16: Compute Accuracy and ROC AUC Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "441e0f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.8551\n",
      "ROC AUC Score: 0.9069\n",
      "Geometric Mean: 0.8552\n",
      "F1 Score: 0.8551\n",
      "PR AUC Score: 0.8457\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, f1_score, precision_recall_curve, auc\n",
    ")\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "# Step 13: Train a Classification Model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)  # Train on resampled data\n",
    "\n",
    "# Step 14: Make Predictions\n",
    "y_pred = clf.predict(X_test)  # Predicted labels\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]  # Probability of positive class\n",
    "\n",
    "# Step 15: Compute Accuracy and ROC AUC Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Compute Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "g_mean = geometric_mean_score(y_test, y_pred)  # Geometric Mean\n",
    "f1 = f1_score(y_test, y_pred)  # F1-score\n",
    "\n",
    "# Compute Precision-Recall Curve and PR AUC\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = auc(recall, precision)  # Area Under Precision-Recall Curve\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"Geometric Mean: {g_mean:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"PR AUC Score: {pr_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
