{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66a6fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import cdist\n",
    "import seaborn as sa\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a827981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the Dataset\n",
    "df = pd.read_csv('crx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "955714df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "  Unnamed: 0 Unnamed: 1  Unnamed: 2 Unnamed: 3 A1 A2 A3    A4 A5 A6  A7 A8 A9  \\\n",
      "0          b      30.83       0.000          u  g  w  v  1.25  t  t   1  f  g   \n",
      "1          a      58.67       4.460          u  g  q  h  3.04  t  t   6  f  g   \n",
      "2          a       24.5       0.500          u  g  q  h  1.50  t  f   0  f  g   \n",
      "3          b      27.83       1.540          u  g  w  v  3.75  t  t   5  t  g   \n",
      "4          b      20.17       5.625          u  g  w  v  1.71  t  f   0  f  s   \n",
      "\n",
      "   A10  A11 Class  \n",
      "0  202    0     +  \n",
      "1   43  560     +  \n",
      "2  280  824     +  \n",
      "3  100    3     +  \n",
      "4  120    0     +  \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Inspect the Dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f315dda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Names:\n",
      "Index(['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'A1', 'A2',\n",
      "       'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11', 'Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a157e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Identify the Target Column (\"Class\")\n",
    "if 'Class' in df.columns:\n",
    "    target_column = 'Class'\n",
    "else:\n",
    "    raise ValueError(\"Class column not found! Please check the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62942f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "        label_encoders[column] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecfe9e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Split Data into Training & Testing Sets\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "652aedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Data Preprocessing (Standardization)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "294a68d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution Before ADASYN:\n",
      "Counter({1: 315, 0: 237})\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Check Class Imbalance\n",
    "print(\"\\nClass Distribution Before ADASYN:\")\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b435b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Apply K-Means Clustering\n",
    "k = 10  # Number of clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d928ee37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clusters: [0 0 0 0 0 0 0 0 0 0 0 0 8 0 0 8 0 0 2 0 0 0 8 8 0 0 0 0 0 5 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 8 0 0 8 0 8 0 0 0 0 8 0 0 0 0 0 2 8 0 0 0 0 5 8 8 3 0 0\n",
      " 3 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 3 0 0 8 8 0 0 0 0 0 0 0 0 3 0 0 0\n",
      " 0 0 0 0 0 0 0 0 5 0 0 5 0 0 5 0 8 0 0 0 2 8 0 0 0 0 3 0 0 0 0 0 3 0 8 8 0\n",
      " 0 0 0 0 0 8 0 0 0 8 0 0 0 0 0 0 0 0 0 0 0 5 0 0 3 8 0 0 0 0 8 0 0 0 0 5 5\n",
      " 0 0 0 0 0 0 0 0 0 6 0 0 0 0 5 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9\n",
      " 0 0 0 0 3 8 0 0 0 0 0 0 0 0 8 0 0 8 0 0 0 0 0 0 0 0 0 0 0 8 0 8 5 2 0 8 0\n",
      " 8 0 0 8 0 9 0 0 0 0 0 0 8 9 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0 0 8 0 0\n",
      " 0 0 0 0 8 0 0 0 0 0 7 0 0 0 8 3 0 0 8 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 8 0 0\n",
      " 8 8 0 0 0 8 0 5 8 0 0 0 0 0 0 5 5 0 0 0 8 0 0 0 0 0 0 0 8 0 8 0 0 0 5 0 8\n",
      " 5 8 0 5 5 0 0 0 0 0 0 8 0 8 0 0 0 0 0 0 0 3 0 8 8 0 8 0 1 0 0 0 8 0 0 8 0\n",
      " 0 0 0 8 3 0 0 0 0 0 5 0 0 0 0 0 8 0 0 0 0 0 8 0 0 0 0 5 7 0 0 0 0 8 0 0 0\n",
      " 3 8 8 0 0 7 0 3 0 8 0 0 0 8 0 0 8 0 0 0 0 0 0 3 0 5 0 3 0 0 0 5 5 0 0 0 0\n",
      " 8 0 0 0 0 0 8 0 3 0 7 8 0 0 0 8 0 0 0 0 0 5 0 8 0 0 0 0 0 0 0 0 4 0 0 0 0\n",
      " 8 0 0 0 5 0 0 0 7 8 0 0 0 5 0 0 0 0 0 8 0 0 8 0 0 0 0 0 8 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClusters:\", clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ff9f8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Filter Clusters with More Minority Instances\n",
    "df_train_clustered = X_train.copy()\n",
    "df_train_clustered['cluster'] = clusters\n",
    "df_train_clustered[target_column] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0078ef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_clusters = []\n",
    "for c in np.unique(clusters):\n",
    "    cluster_data = df_train_clustered[df_train_clustered['cluster'] == c]\n",
    "    minority_count = cluster_data[target_column].sum()\n",
    "    majority_count = len(cluster_data) - minority_count\n",
    "    imbalance_ratio = (majority_count + 1) / (minority_count + 1)\n",
    "    if imbalance_ratio < 1.5:\n",
    "        filtered_clusters.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26c072e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Clusters: [0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFiltered Clusters:\", filtered_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "204ff9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Compute Sampling Weight for Each Cluster\n",
    "def compute_sampling_weight(cluster_data, target_column, minority_count, X_train):\n",
    "    feature_data = cluster_data.drop(columns=['cluster', target_column]).values\n",
    "    \n",
    "    # Compute pairwise Euclidean distances\n",
    "    pairwise_distances = cdist(feature_data, feature_data, metric='euclidean')\n",
    "    \n",
    "    # Take the mean of the upper triangle (excluding diagonal)\n",
    "    avg_minority_dist = np.mean(pairwise_distances[np.triu_indices(len(feature_data), k=1)])\n",
    "    \n",
    "    print(f\"Cluster {cluster_data['cluster'].iloc[0]} - Avg Euclidean Distance:\", avg_minority_dist)\n",
    "    \n",
    "    density_factor = minority_count / (avg_minority_dist ** X_train.shape[1])\n",
    "    sparsity_factor = 1 / density_factor\n",
    "    \n",
    "    return sparsity_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b830bae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 - Avg Euclidean Distance: 181.47762984596065\n"
     ]
    }
   ],
   "source": [
    "sparsity_sum = sum(compute_sampling_weight(\n",
    "    df_train_clustered[df_train_clustered['cluster'] == f], \n",
    "    target_column, \n",
    "    len(df_train_clustered[df_train_clustered['cluster'] == f]), \n",
    "    X_train\n",
    ") for f in filtered_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceabc7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 - Avg Euclidean Distance: 181.47762984596065\n"
     ]
    }
   ],
   "source": [
    "sampling_weights = {\n",
    "    f: compute_sampling_weight(df_train_clustered[df_train_clustered['cluster'] == f], target_column, len(df_train_clustered[df_train_clustered['cluster'] == f]), X_train) / sparsity_sum\n",
    "    for f in filtered_clusters\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0b0a0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling Weights: {0: 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSampling Weights:\", sampling_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aba4324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Apply ADASYN for Oversampling\n",
    "X_resampled = pd.DataFrame()\n",
    "y_resampled = pd.Series(dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc25fd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_id in filtered_clusters:\n",
    "    cluster_data = df_train_clustered[df_train_clustered['cluster'] == cluster_id]\n",
    "    X_cluster = cluster_data.drop(columns=['cluster', target_column])\n",
    "    y_cluster = cluster_data[target_column]\n",
    "    \n",
    "    num_samples = int(len(y_train) * sampling_weights[cluster_id])\n",
    "    \n",
    "    if len(y_cluster) < 2:  # Skip clusters with fewer than 2 samples\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        adasyn = ADASYN(n_neighbors=min(len(y_cluster) - 1, 3), random_state=42)\n",
    "        X_cluster_resampled, y_cluster_resampled = adasyn.fit_resample(X_cluster, y_cluster)\n",
    "        X_resampled = pd.concat([X_resampled, X_cluster_resampled])\n",
    "        y_resampled = pd.concat([y_resampled, y_cluster_resampled])\n",
    "    except ValueError:\n",
    "        print(f\"Skipping cluster {cluster_id} due to ADASYN resampling issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4da3d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution After ADASYN:\n",
      "Counter({0: 300, 1: 286})\n"
     ]
    }
   ],
   "source": [
    "# Step 13: Check Class Distribution After ADASYN\n",
    "print(\"\\nClass Distribution After ADASYN:\")\n",
    "print(Counter(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd4e333e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 14: Train a Classification Model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44a49e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 15: Make Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "582a905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 16: Compute Accuracy and ROC AUC Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bc99318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.8188\n",
      "ROC AUC Score: 0.8925\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d2a7630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7899\n",
      "ROC AUC Score: 0.8284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Step 15: Make Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Step 16: Compute Accuracy and ROC AUC Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48e186d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.8188\n",
      "ROC AUC Score: 0.8925\n",
      "Geometric Mean: 0.8189\n",
      "F1 Score: 0.8201\n",
      "PR AUC Score: 0.8468\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, f1_score, precision_recall_curve, auc\n",
    ")\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "# Step 13: Train a Classification Model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)  # Train on resampled data\n",
    "\n",
    "# Step 14: Make Predictions\n",
    "y_pred = clf.predict(X_test)  # Predicted labels\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]  # Probability of positive class\n",
    "\n",
    "# Step 15: Compute Accuracy and ROC AUC Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Compute Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "g_mean = geometric_mean_score(y_test, y_pred)  # Geometric Mean\n",
    "f1 = f1_score(y_test, y_pred)  # F1-score\n",
    "\n",
    "# Compute Precision-Recall Curve and PR AUC\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = auc(recall, precision)  # Area Under Precision-Recall Curve\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"Geometric Mean: {g_mean:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"PR AUC Score: {pr_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
