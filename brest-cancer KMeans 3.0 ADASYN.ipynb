{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66a6fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import cdist\n",
    "import seaborn as sa\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a827981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the Dataset\n",
    "file_path = \"breast-cancer.csv\"  # Adjust file path if needed\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "955714df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "                  Class    Age Menopause Tumor_Size Inv_Nodes Node_Caps  \\\n",
      "0  no-recurrence-events  30-39   premeno      30-34       0-2        no   \n",
      "1  no-recurrence-events  40-49   premeno      20-24       0-2        no   \n",
      "2  no-recurrence-events  40-49   premeno      20-24       0-2        no   \n",
      "3  no-recurrence-events  60-69      ge40      15-19       0-2        no   \n",
      "4  no-recurrence-events  40-49   premeno        0-4       0-2        no   \n",
      "\n",
      "   Deg_Malig Breast Breast_Quad Irradiat  \n",
      "0          3   left    left_low       no  \n",
      "1          2  right    right_up       no  \n",
      "2          2   left    left_low       no  \n",
      "3          2  right     left_up       no  \n",
      "4          2  right   right_low       no  \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Inspect the Dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f315dda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Names:\n",
      "Index(['Class', 'Age', 'Menopause', 'Tumor_Size', 'Inv_Nodes', 'Node_Caps',\n",
      "       'Deg_Malig', 'Breast', 'Breast_Quad', 'Irradiat'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a157e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Identify the Target Column (\"Class\")\n",
    "if 'Class' in df.columns:\n",
    "    target_column = 'Class'\n",
    "else:\n",
    "    raise ValueError(\"Class column not found! Please check the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62942f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "        label_encoders[column] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecfe9e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Split Data into Training & Testing Sets\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "652aedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Data Preprocessing (Standardization)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "294a68d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution Before ADASYN:\n",
      "Counter({0: 164, 1: 64})\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Check Class Imbalance\n",
    "print(\"\\nClass Distribution Before ADASYN:\")\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b435b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Apply K-Means Clustering\n",
    "k = 10  # Number of clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d928ee37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clusters: [7 9 4 8 7 0 1 0 9 6 0 6 0 4 0 0 8 4 3 0 5 4 2 2 6 4 0 6 3 6 8 1 7 9 3 4 4\n",
      " 4 7 0 6 0 0 4 9 3 9 7 9 8 7 6 4 9 3 8 0 3 3 4 0 9 1 6 0 6 8 2 3 5 5 0 6 7\n",
      " 4 2 8 8 4 3 3 3 6 6 6 3 9 2 3 4 4 7 7 4 7 6 8 6 2 0 8 0 9 9 9 4 9 5 7 4 3\n",
      " 5 0 2 4 6 0 3 6 3 0 6 3 9 3 7 1 2 4 0 9 5 9 3 8 7 3 2 6 4 6 9 4 2 5 9 3 9\n",
      " 9 3 9 9 9 3 5 5 0 9 3 7 5 6 4 9 4 1 7 8 7 0 4 3 0 3 1 4 0 4 6 6 4 4 5 0 2\n",
      " 3 5 7 4 4 2 9 0 4 8 6 6 8 1 4 1 4 9 4 4 6 6 7 9 2 4 9 9 0 6 5 6 9 4 6 4 6\n",
      " 6 3 9 0 8 7]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClusters:\", clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ff9f8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Filter Clusters with More Minority Instances\n",
    "df_train_clustered = X_train.copy()\n",
    "df_train_clustered['cluster'] = clusters\n",
    "df_train_clustered[target_column] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0078ef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_clusters = []\n",
    "for c in np.unique(clusters):\n",
    "    cluster_data = df_train_clustered[df_train_clustered['cluster'] == c]\n",
    "    minority_count = cluster_data[target_column].sum()\n",
    "    majority_count = len(cluster_data) - minority_count\n",
    "    imbalance_ratio = (majority_count + 1) / (minority_count + 1)\n",
    "    if imbalance_ratio < 1.5:\n",
    "        filtered_clusters.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26c072e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Clusters: [5, 8]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFiltered Clusters:\", filtered_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "204ff9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Compute Sampling Weight for Each Cluster\n",
    "def compute_sampling_weight(cluster_data, target_column, minority_count, X_train):\n",
    "    feature_data = cluster_data.drop(columns=['cluster', target_column]).values\n",
    "    \n",
    "    # Compute pairwise Euclidean distances\n",
    "    pairwise_distances = cdist(feature_data, feature_data, metric='euclidean')\n",
    "    \n",
    "    # Take the mean of the upper triangle (excluding diagonal)\n",
    "    avg_minority_dist = np.mean(pairwise_distances[np.triu_indices(len(feature_data), k=1)])\n",
    "    \n",
    "    print(f\"Cluster {cluster_data['cluster'].iloc[0]} - Avg Euclidean Distance:\", avg_minority_dist)\n",
    "    \n",
    "    density_factor = minority_count / (avg_minority_dist ** X_train.shape[1])\n",
    "    sparsity_factor = 1 / density_factor\n",
    "    \n",
    "    return sparsity_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b830bae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 5 - Avg Euclidean Distance: 3.5470667989844005\n",
      "Cluster 8 - Avg Euclidean Distance: 2.851448313223268\n"
     ]
    }
   ],
   "source": [
    "sparsity_sum = sum(compute_sampling_weight(\n",
    "    df_train_clustered[df_train_clustered['cluster'] == f], \n",
    "    target_column, \n",
    "    len(df_train_clustered[df_train_clustered['cluster'] == f]), \n",
    "    X_train\n",
    ") for f in filtered_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceabc7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 5 - Avg Euclidean Distance: 3.5470667989844005\n",
      "Cluster 8 - Avg Euclidean Distance: 2.851448313223268\n"
     ]
    }
   ],
   "source": [
    "sampling_weights = {\n",
    "    f: compute_sampling_weight(df_train_clustered[df_train_clustered['cluster'] == f], target_column, len(df_train_clustered[df_train_clustered['cluster'] == f]), X_train) / sparsity_sum\n",
    "    for f in filtered_clusters\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0b0a0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling Weights: {5: 0.8916538216995122, 8: 0.10834617830048776}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSampling Weights:\", sampling_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aba4324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Apply ADASYN for Oversampling\n",
    "X_resampled = pd.DataFrame()\n",
    "y_resampled = pd.Series(dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc25fd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping cluster 8 due to ADASYN resampling issues.\n"
     ]
    }
   ],
   "source": [
    "for cluster_id in filtered_clusters:\n",
    "    cluster_data = df_train_clustered[df_train_clustered['cluster'] == cluster_id]\n",
    "    X_cluster = cluster_data.drop(columns=['cluster', target_column])\n",
    "    y_cluster = cluster_data[target_column]\n",
    "    \n",
    "    num_samples = int(len(y_train) * sampling_weights[cluster_id])\n",
    "    \n",
    "    if len(y_cluster) < 2:  # Skip clusters with fewer than 2 samples\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        adasyn = ADASYN(n_neighbors=min(len(y_cluster) - 1, 3), random_state=42)\n",
    "        X_cluster_resampled, y_cluster_resampled = adasyn.fit_resample(X_cluster, y_cluster)\n",
    "        X_resampled = pd.concat([X_resampled, X_cluster_resampled])\n",
    "        y_resampled = pd.concat([y_resampled, y_cluster_resampled])\n",
    "    except ValueError:\n",
    "        print(f\"Skipping cluster {cluster_id} due to ADASYN resampling issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4da3d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution After ADASYN:\n",
      "Counter({1: 8, 0: 8})\n"
     ]
    }
   ],
   "source": [
    "# Step 13: Check Class Distribution After ADASYN\n",
    "print(\"\\nClass Distribution After ADASYN:\")\n",
    "print(Counter(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd4e333e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 14: Train a Classification Model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44a49e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 15: Make Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "582a905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 16: Compute Accuracy and ROC AUC Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bc99318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.6552\n",
      "ROC AUC Score: 0.7471\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d2a7630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.6379\n",
      "ROC AUC Score: 0.6139\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Step 15: Make Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Step 16: Compute Accuracy and ROC AUC Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07f71601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.6552\n",
      "ROC AUC Score: 0.7471\n",
      "Geometric Mean: 0.6467\n",
      "F1 Score: 0.5652\n",
      "PR AUC Score: 0.6795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, f1_score, precision_recall_curve, auc\n",
    ")\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "# Step 13: Train a Classification Model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)  # Train on resampled data\n",
    "\n",
    "# Step 14: Make Predictions\n",
    "y_pred = clf.predict(X_test)  # Predicted labels\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]  # Probability of positive class\n",
    "\n",
    "# Step 15: Compute Accuracy and ROC AUC Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Compute Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "g_mean = geometric_mean_score(y_test, y_pred)  # Geometric Mean\n",
    "f1 = f1_score(y_test, y_pred)  # F1-score\n",
    "\n",
    "# Compute Precision-Recall Curve and PR AUC\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = auc(recall, precision)  # Area Under Precision-Recall Curve\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"Geometric Mean: {g_mean:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"PR AUC Score: {pr_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
